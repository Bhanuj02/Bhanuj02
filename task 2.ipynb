{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import datasets","metadata":{"execution":{"iopub.status.busy":"2021-06-10T13:42:52.120783Z","iopub.execute_input":"2021-06-10T13:42:52.121224Z","iopub.status.idle":"2021-06-10T13:42:53.178123Z","shell.execute_reply.started":"2021-06-10T13:42:52.12114Z","shell.execute_reply":"2021-06-10T13:42:53.177129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the iris dataset\niris = datasets.load_iris()\niris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\niris_df.head() # See the first 5 rows","metadata":{"execution":{"iopub.status.busy":"2021-06-10T13:43:13.739534Z","iopub.execute_input":"2021-06-10T13:43:13.740056Z","iopub.status.idle":"2021-06-10T13:43:13.777571Z","shell.execute_reply.started":"2021-06-10T13:43:13.740021Z","shell.execute_reply":"2021-06-10T13:43:13.776367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the elbow method to find the optimal number of clusters\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 15):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 30)\n    kmeans.fit(iris_df)\n    wcss.append(kmeans.inertia_) \n    # kmeans.inertia_ returns SSE\nplt.plot(range(1, 15), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T13:45:05.990253Z","iopub.execute_input":"2021-06-10T13:45:05.990772Z","iopub.status.idle":"2021-06-10T13:45:06.740063Z","shell.execute_reply.started":"2021-06-10T13:45:05.990726Z","shell.execute_reply":"2021-06-10T13:45:06.739264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42) #K-Means++ is used to avoid random cenroid trap\ny_kmeans = kmeans.fit_predict(iris_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T13:45:41.06028Z","iopub.execute_input":"2021-06-10T13:45:41.060795Z","iopub.status.idle":"2021-06-10T13:45:41.09894Z","shell.execute_reply.started":"2021-06-10T13:45:41.060762Z","shell.execute_reply":"2021-06-10T13:45:41.097988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualising the clusters - On the first two columns\nx = iris_df.iloc[:, [0, 1, 2, 3]].values\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], \n            s = 100, c = 'red', label = 'Iris-setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], \n            s = 100, c = 'blue', label = 'Iris-versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],\n            s = 100, c = 'green', label = 'Iris-virginica')\n\n# Plotting the centroids of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], \n            s = 100, c = 'yellow', label = 'Centroids')\n\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T13:45:55.671143Z","iopub.execute_input":"2021-06-10T13:45:55.671731Z","iopub.status.idle":"2021-06-10T13:45:55.943942Z","shell.execute_reply.started":"2021-06-10T13:45:55.671696Z","shell.execute_reply":"2021-06-10T13:45:55.942861Z"},"trusted":true},"execution_count":null,"outputs":[]}]}